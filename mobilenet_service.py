from ray import serve
from fastapi import HTTPException
import torch
from torchvision import models, transforms
from PIL import Image
import io
from typing import Dict, Any, List
from weights_manager import WeightsManager

# Available classification tasks
AVAILABLE_TASKS = ["body_volume", "feet", "gender", "glasses", "hairstyle"]

@serve.deployment(
    name="mobilenet_classifier"
)
class MobilenetClassifier:
    def __init__(self):
        print("üîπ Loading MobileNet models from Hugging Face...")
        
        self.models = {}
        self.labels = {}
        self.weights_manager = WeightsManager()
        
        # Load t·∫•t c·∫£ c√°c MobileNet weights t·ª´ Hugging Face
        self._load_all_models()
        
        # Preprocessing pipeline
        self.preprocess = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    def _load_all_models(self):
        """Load t·∫•t c·∫£ c√°c MobileNet models t·ª´ Hugging Face"""
        try:
            # Get available weights t·ª´ Hugging Face
            weights_info = self.weights_manager.get_available_weights()
            mobilenet_tasks = weights_info.get("mobilenet", [])
            
            if not mobilenet_tasks:
                print("‚ö†Ô∏è  No MobileNet weights found on Hugging Face")
                return
            
            print(f"üîç Found MobileNet tasks on Hugging Face: {mobilenet_tasks}")
            
            # Load t·ª´ng model
            for task_name in mobilenet_tasks:
                try:
                    print(f"üì• Loading MobileNetV2 model for task: {task_name}")
                    num_classes = len(self._generate_labels_for_task(task_name))
                    model = models.mobilenet_v2(weights=None, num_classes=num_classes)
            
                    state_dict = self.weights_manager.load_model_state_dict("mobilenet", task_name)
                    if state_dict is None:
                        print(f"‚ùå Failed to load weights for task '{task_name}'")
                        continue
            
                    model.load_state_dict(state_dict, strict=False)
                    model.eval()
                    self.models[task_name] = model
                    self.labels[task_name] = self._generate_labels_for_task(task_name)
                    print(f"‚úÖ Loaded MobileNetV2 model for task: {task_name}")
            
                except Exception as e:
                    print(f"‚ùå Error loading model for task '{task_name}': {e}")

            
            print(f"üìä Loaded {len(self.models)} MobileNet models: {list(self.models.keys())}")
            
        except Exception as e:
            print(f"‚ùå Error in _load_all_models: {e}")
            print("üí° Falling back to available tasks list")
            # Fallback - try to load t·ª´ng task manually
            for task_name in AVAILABLE_TASKS:
                try:
                    state_dict = self.weights_manager.load_model_state_dict("mobilenet", task_name)
                    if state_dict:
                        model = models.mobilenet_v2(weights=None)
                        model.load_state_dict(state_dict, strict=False)
                        model.eval()
                        self.models[task_name] = model
                        self.labels[task_name] = self._generate_labels_for_task(task_name)
                        print(f"‚úÖ Loaded MobileNet model for task: {task_name}")
                except Exception as e:
                    print(f"‚ùå Failed to load task '{task_name}': {e}")

    def _generate_labels_for_task(self, task_name: str) -> List[str]:
        """Generate labels cho t·ª´ng task"""
        if task_name == "gender":
            return ["male", "female"]
        elif task_name == "glasses":
            return ["yes", "sunglass", "no"]
        elif task_name == "body_volume":
            return ["thin", "medium", "fat", "unknown"]
        elif task_name == "feet":
            return ["sport", "classic", "high heels", "boots", "sandals", "nothing"]
        elif task_name == "hairstyle":
            return ["bald", "short", "medium", "long", "horse tail"]
        else:
            # Default labels n·∫øu kh√¥ng bi·∫øt task
            return [f"class_{i}" for i in range(2)]  # Default 2 classes

    async def predict(self, image_bytes: bytes, task: str = "gender") -> Dict[str, Any]:
        """Classify image using MobileNet for specific task"""
        try:
            if task not in self.models:
                raise HTTPException(status_code=400, detail=f"Task '{task}' not available. Available tasks: {list(self.models.keys())}")
            
            # Load v√† preprocess image
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            input_tensor = self.preprocess(image).unsqueeze(0)

            # Get model cho task
            model = self.models[task]
            labels = self.labels[task]

            # Inference
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                
                # Get predictions for all classes
                results = []
                for i, prob in enumerate(probabilities):
                    if i < len(labels):
                        results.append({
                            "label": labels[i],
                            "confidence": float(prob.item())
                        })

            return {
                "model": "mobilenet",
                "task": task,
                "predictions": results
            }
            
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Image processing error: {str(e)}")

        # Gi·ªØ l·∫°i __call__ n·∫øu c·∫ßn endpoint m·∫∑c ƒë·ªãnh, nh∆∞ng n√≥ kh√¥ng c√≤n l√† predict n·ªØa
    async def __call__(self, *args, **kwargs):
        # N·∫øu Router g·ªçi handle.remote() thay v√¨ handle.predict.remote(), 
        # Ray s·∫Ω g·ªçi h√†m n√†y. Ta c√≥ th·ªÉ chuy·ªÉn h∆∞·ªõng n√≥ ƒë·∫øn predict.
        if len(args) >= 1 and isinstance(args[0], bytes):
            return await self.predict(*args, **kwargs)
        
        # H√†m n√†y kh√¥ng n√™n ƒë∆∞·ª£c g·ªçi tr·ª±c ti·∫øp qua HTTP v√¨ Router ƒë√£ ƒë·ªãnh tuy·∫øn r√µ r√†ng.
        return {"error": "Use the /predict endpoint or call the predict method."}

    async def get_available_tasks(self) -> List[str]:
        """Get available tasks"""
        return list(self.models.keys())

def app(config: dict | None = None):
    # Expose only the internal classifier deployment (no HTTP routes)
    return MobilenetClassifier.bind()