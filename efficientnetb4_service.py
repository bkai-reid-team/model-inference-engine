from ray import serve
from fastapi import HTTPException
import torch
from torchvision import models, transforms
from PIL import Image
import io
from typing import Dict, Any, List
from weights_manager import WeightsManager

# Available classification tasks (Cáº§n pháº£i khá»›p vá»›i nhá»¯ng gÃ¬ WeightsManager tráº£ vá»)
AVAILABLE_TASKS = ["body_volume", "feet", "gender", "glasses", "hairstyle"]

# TÃªn class deployment
@serve.deployment(
    name="efficientnet_b4_classifier"
)
class EfficientNetB4Classifier:
    def __init__(self):
        print("ðŸ”¹ Loading EfficientNetB4 models...")
        
        # XÃ¡c Ä‘á»‹nh thiáº¿t bá»‹ (GPU hoáº·c CPU)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"âš™ï¸ Using device: {self.device}")
        
        self.models = {}
        self.labels = {}
        self.weights_manager = WeightsManager()
        
        # Load táº¥t cáº£ cÃ¡c EfficientNetB4 weights
        self._load_all_models()
        
        # Preprocessing pipeline
        self.preprocess = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    def _load_all_models(self):
        """Load táº¥t cáº£ cÃ¡c EfficientNetB4 models"""
        try:
            # Get available weights
            weights_info = self.weights_manager.get_available_weights()
            efficientnet_b4_tasks = weights_info.get("efficientnet_b4", [])
            
            if not efficientnet_b4_tasks:
                print("âš ï¸ No EfficientNetB4 weights found.")
                return
            
            print(f"ðŸ” Found EfficientNetB4 tasks: {efficientnet_b4_tasks}")
            
            # Load tá»«ng model
            for task_name in efficientnet_b4_tasks:
                try:
                    print(f"ðŸ“¥ Loading EfficientNetB4 model for task: {task_name}")
                    
                    # âœ… XÃ¡c Ä‘á»‹nh sá»‘ lá»›p Ä‘Ãºng cho tá»«ng task
                    num_classes = len(self._generate_labels_for_task(task_name))
                    
                    # âœ… Táº¡o model vá»›i sá»‘ lá»›p tÆ°Æ¡ng á»©ng
                    model = models.efficientnet_b4(weights=None, num_classes=num_classes)
                    
                    # Load state dict
                    state_dict = self.weights_manager.load_model_state_dict("efficientnet_b4", task_name)
                    if state_dict is None:
                        print(f"âŒ Failed to load weights for task '{task_name}'")
                        continue
            
                    # Load weights vÃ o model
                    model.load_state_dict(state_dict, strict=False)
                    
                    # Chuyá»ƒn model sang GPU/thiáº¿t bá»‹ Ä‘Ã£ chá»n
                    model.to(self.device)
                    model.eval()
                    
                    # LÆ°u model vÃ  nhÃ£n
                    self.models[task_name] = model
                    self.labels[task_name] = self._generate_labels_for_task(task_name)
                    
                    print(f"âœ… Loaded EfficientNetB4 model for task: {task_name}")
            
                except Exception as e:
                    print(f"âŒ Error loading model for task '{task_name}': {e}")
                    raise 
            
            print(f"ðŸ“Š Loaded {len(self.models)} EfficientNetB4 models: {list(self.models.keys())}")
            
        except Exception as e:
            print(f"âŒ Critical Error in _load_all_models: {e}")
            raise 

    def _generate_labels_for_task(self, task_name: str) -> List[str]:
        """Generate labels cho tá»«ng task"""
        if task_name == "gender":
            return ["male", "female"]
        elif task_name == "glasses":
            return ["yes", "sunglass", "no"]
        elif task_name == "body_volume":
            return ["thin", "medium", "fat", "unknown"]
        elif task_name == "feet":
            return ["sport", "classic", "high heels", "boots", "sandals", "nothing"]
        elif task_name == "hairstyle":
            return ["bald", "short", "medium", "long", "horse tail"]
        else:
            # Default labels náº¿u khÃ´ng biáº¿t task
            return [f"class_{i}" for i in range(2)]  # Default 2 classes

    # FIX: Äá»‹nh nghÄ©a hÃ m predict rÃµ rÃ ng mÃ  Router Ä‘ang tÃ¬m kiáº¿m.
    async def predict(self, image_bytes: bytes, task: str = "gender") -> Dict[str, Any]:
        """Classify image using EfficientNetB4 for specific task"""
        # ToÃ n bá»™ logic xá»­ lÃ½ áº£nh Ä‘Æ°á»£c chuyá»ƒn tá»« __call__ sang Ä‘Ã¢y
        try:
            if task not in self.models:
                raise HTTPException(status_code=400, detail=f"Task '{task}' not available. Available tasks: {list(self.models.keys())}")
            
            # Load vÃ  preprocess image
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            # Chuyá»ƒn input_tensor sang thiáº¿t bá»‹ (GPU)
            input_tensor = self.preprocess(image).unsqueeze(0).to(self.device)

            # Get model cho task
            model = self.models[task]
            labels = self.labels[task]

            # Inference
            with torch.no_grad():
                outputs = model(input_tensor)
                probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                
                # Get predictions for all classes
                results = []
                for i, prob in enumerate(probabilities):
                    if i < len(labels):
                        results.append({
                            "label": labels[i],
                            "confidence": float(prob.item())
                        })

            return {
                "model": "efficientnet_b4",
                "task": task,
                "predictions": results
            }
            
        except HTTPException:
            raise
        except Exception as e:
            # NÃ¢ng lá»—i lÃªn HTTP 500 Ä‘á»ƒ client tháº¥y
            raise HTTPException(status_code=500, detail=f"Image processing error: {str(e)}")


    # Giá»¯ láº¡i __call__ náº¿u cáº§n endpoint máº·c Ä‘á»‹nh, nhÆ°ng nÃ³ khÃ´ng cÃ²n lÃ  predict ná»¯a
    async def __call__(self, *args, **kwargs):
        # Náº¿u Router gá»i handle.remote() thay vÃ¬ handle.predict.remote(), 
        # Ray sáº½ gá»i hÃ m nÃ y. Ta cÃ³ thá»ƒ chuyá»ƒn hÆ°á»›ng nÃ³ Ä‘áº¿n predict.
        if len(args) >= 1 and isinstance(args[0], bytes):
            return await self.predict(*args, **kwargs)
        
        # HÃ m nÃ y khÃ´ng nÃªn Ä‘Æ°á»£c gá»i trá»±c tiáº¿p qua HTTP vÃ¬ Router Ä‘Ã£ Ä‘á»‹nh tuyáº¿n rÃµ rÃ ng.
        return {"error": "Use the /predict endpoint or call the predict method."}


    async def get_available_tasks(self) -> List[str]:
        """Get available tasks"""
        return list(self.models.keys())

def app(config: dict | None = None):
    # Expose only the internal classifier deployment (no HTTP routes)
    return EfficientNetB4Classifier.bind()